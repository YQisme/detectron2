{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [27], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjpg\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpng\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     23\u001b[0m         \u001b[38;5;28mlist\u001b[39m\u001b[38;5;241m.\u001b[39mappend(filename)\n\u001b[0;32m---> 24\u001b[0m predictor \u001b[38;5;241m=\u001b[39m \u001b[43mDefaultPredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m random\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m     26\u001b[0m     im \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./balloon/val/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m d)\n",
      "File \u001b[0;32m~/yq/detectron2/detectron2/engine/defaults.py:282\u001b[0m, in \u001b[0;36mDefaultPredictor.__init__\u001b[0;34m(self, cfg)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, cfg):\n\u001b[1;32m    281\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcfg \u001b[39m=\u001b[39m cfg\u001b[39m.\u001b[39mclone()  \u001b[39m# cfg can be modified by model\u001b[39;00m\n\u001b[0;32m--> 282\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m build_model(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcfg)\n\u001b[1;32m    283\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39meval()\n\u001b[1;32m    284\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(cfg\u001b[39m.\u001b[39mDATASETS\u001b[39m.\u001b[39mTEST):\n",
      "File \u001b[0;32m~/yq/detectron2/detectron2/modeling/meta_arch/build.py:23\u001b[0m, in \u001b[0;36mbuild_model\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m     21\u001b[0m meta_arch \u001b[39m=\u001b[39m cfg\u001b[39m.\u001b[39mMODEL\u001b[39m.\u001b[39mMETA_ARCHITECTURE\n\u001b[1;32m     22\u001b[0m model \u001b[39m=\u001b[39m META_ARCH_REGISTRY\u001b[39m.\u001b[39mget(meta_arch)(cfg)\n\u001b[0;32m---> 23\u001b[0m model\u001b[39m.\u001b[39;49mto(torch\u001b[39m.\u001b[39;49mdevice(cfg\u001b[39m.\u001b[39;49mMODEL\u001b[39m.\u001b[39;49mDEVICE))\n\u001b[1;32m     24\u001b[0m _log_api_usage(\u001b[39m\"\u001b[39m\u001b[39mmodeling.meta_arch.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m meta_arch)\n\u001b[1;32m     25\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/develop/Anaconda3/envs/detectron2/lib/python3.8/site-packages/torch/nn/modules/module.py:927\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    924\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m    925\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m--> 927\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
      "File \u001b[0;32m~/develop/Anaconda3/envs/detectron2/lib/python3.8/site-packages/torch/nn/modules/module.py:579\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    578\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 579\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    581\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    583\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    584\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    590\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/develop/Anaconda3/envs/detectron2/lib/python3.8/site-packages/torch/nn/modules/module.py:579\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    578\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 579\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    581\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    583\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    584\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    590\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/develop/Anaconda3/envs/detectron2/lib/python3.8/site-packages/torch/nn/modules/module.py:602\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    601\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 602\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[1;32m    603\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    604\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/develop/Anaconda3/envs/detectron2/lib/python3.8/site-packages/torch/nn/modules/module.py:925\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[1;32m    923\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    924\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m--> 925\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "cfg = get_cfg()  # 获取新配置\n",
    "cfg.merge_from_file(\n",
    "    model_zoo.get_config_file(\"COCO-Keypoints/keypoint_rcnn_R_50_FPN_3x.yaml\")\n",
    ")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7  # 给模型设置阈值\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\n",
    "    \"COCO-Keypoints/keypoint_rcnn_R_50_FPN_3x.yaml\"\n",
    ")\n",
    "\n",
    "list = []\n",
    "for filename in os.listdir(\"./balloon/val\"):\n",
    "    if filename.endswith(\"jpg\") or filename.endswith(\"png\"):\n",
    "        list.append(filename)\n",
    "predictor = DefaultPredictor(cfg)\n",
    "for d in random.sample(list, 3):\n",
    "    im = cv2.imread(\"./balloon/val/\" + d)\n",
    "    outputs = predictor(im)\n",
    "    v = Visualizer(\n",
    "        im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2\n",
    "    )\n",
    "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    plt.figure()\n",
    "    plt.imshow(out.get_image()[:, :, ::-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4581425993_72b9b15fc0_b.jpg', '3800636873_ace2c2795f_b.jpg', '8053085540_a72bd21a64_k.jpg', '16335852991_f55de7958d_k.jpg', '4838031651_3e7b5ea5c7_b.jpg', '5603212091_2dfe16ea72_b.jpg', '24631331976_defa3bb61f_k.jpg', '2917282960_06beee649a_b.jpg', '14898532020_ba6199dd22_k.jpg', '3825919971_93fb1ec581_b.jpg', '6810773040_3d81036d05_k.jpg', '5555705118_3390d70abe_b.jpg', '410488422_5f8991f26e_b.jpg']\n",
      "./balloon/val5555705118_3390d70abe_b.jpg\n",
      "[[[ 58  88 137]\n",
      "  [ 60  90 139]\n",
      "  [ 63  90 140]\n",
      "  ...\n",
      "  [ 82 113 138]\n",
      "  [ 81 112 137]\n",
      "  [ 80 111 136]]\n",
      "\n",
      " [[ 57  87 136]\n",
      "  [ 59  89 138]\n",
      "  [ 61  88 138]\n",
      "  ...\n",
      "  [ 81 115 139]\n",
      "  [ 80 114 138]\n",
      "  [ 79 113 137]]\n",
      "\n",
      " [[ 55  85 134]\n",
      "  [ 57  87 136]\n",
      "  [ 59  86 136]\n",
      "  ...\n",
      "  [ 80 116 140]\n",
      "  [ 79 115 139]\n",
      "  [ 78 114 138]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 22  20  19]\n",
      "  [ 22  20  19]\n",
      "  [ 21  19  18]\n",
      "  ...\n",
      "  [165 170 171]\n",
      "  [165 170 171]\n",
      "  [164 169 170]]\n",
      "\n",
      " [[ 21  19  18]\n",
      "  [ 21  19  18]\n",
      "  [ 21  19  18]\n",
      "  ...\n",
      "  [164 169 170]\n",
      "  [164 169 170]\n",
      "  [164 169 170]]\n",
      "\n",
      " [[ 19  17  16]\n",
      "  [ 19  17  16]\n",
      "  [ 20  18  17]\n",
      "  ...\n",
      "  [165 170 171]\n",
      "  [165 170 171]\n",
      "  [165 170 171]]]\n",
      "./balloon/val6810773040_3d81036d05_k.jpg\n",
      "[[[174 184 171]\n",
      "  [175 185 173]\n",
      "  [175 185 173]\n",
      "  ...\n",
      "  [229 250 252]\n",
      "  [230 251 253]\n",
      "  [230 251 253]]\n",
      "\n",
      " [[174 184 171]\n",
      "  [175 185 173]\n",
      "  [175 184 174]\n",
      "  ...\n",
      "  [230 251 253]\n",
      "  [230 251 253]\n",
      "  [230 251 253]]\n",
      "\n",
      " [[174 184 172]\n",
      "  [175 185 173]\n",
      "  [175 184 174]\n",
      "  ...\n",
      "  [230 251 253]\n",
      "  [230 251 253]\n",
      "  [230 251 253]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 22  23  27]\n",
      "  [ 23  24  28]\n",
      "  [ 23  25  26]\n",
      "  ...\n",
      "  [ 48  49  53]\n",
      "  [ 49  50  54]\n",
      "  [ 49  50  54]]\n",
      "\n",
      " [[ 24  25  29]\n",
      "  [ 23  24  28]\n",
      "  [ 23  24  28]\n",
      "  ...\n",
      "  [ 48  50  51]\n",
      "  [ 49  51  52]\n",
      "  [ 50  52  53]]\n",
      "\n",
      " [[ 27  26  30]\n",
      "  [ 24  25  29]\n",
      "  [ 24  25  29]\n",
      "  ...\n",
      "  [ 48  50  51]\n",
      "  [ 49  51  52]\n",
      "  [ 49  51  52]]]\n",
      "./balloon/val4581425993_72b9b15fc0_b.jpg\n",
      "[[[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "list=[]\n",
    "for filename in os.listdir(\"./balloon/val\"):\n",
    "    if filename.endswith(\"jpg\") or filename.endswith(\"png\"):\n",
    "        list.append(filename)\n",
    "print(list)\n",
    "for d in random.sample(list, 3):\n",
    "    print(\"./balloon/val\"+d)\n",
    "    im = cv2.imread(\"./balloon/val/\"+d)\n",
    "    print(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Chooses k unique random elements from a population sequence or set.\n",
      "\n",
      "Returns a new list containing elements from the population while\n",
      "leaving the original population unchanged.  The resulting list is\n",
      "in selection order so that all sub-slices will also be valid random\n",
      "samples.  This allows raffle winners (the sample) to be partitioned\n",
      "into grand prize and second place winners (the subslices).\n",
      "\n",
      "Members of the population need not be hashable or unique.  If the\n",
      "population contains repeats, then each occurrence is a possible\n",
      "selection in the sample.\n",
      "\n",
      "To choose a sample in a range of integers, use range as an argument.\n",
      "This is especially fast and space efficient for sampling from a\n",
      "large population:   sample(range(10000000), 60)\n",
      "\u001b[0;31mFile:\u001b[0m      ~/develop/Anaconda3/envs/detectron2/lib/python3.8/random.py\n",
      "\u001b[0;31mType:\u001b[0m      method\n"
     ]
    }
   ],
   "source": [
    "?random.sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2917282960_06beee649a_b.jpg\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "for d in random.sample(list,1):\n",
    "    print(d)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('detectron2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1bdad268a850e50b027b5fb8885ee6e1843e01f46bad91a3f1d9767c45f6d421"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
